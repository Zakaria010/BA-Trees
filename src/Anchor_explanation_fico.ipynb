{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RglSzukolsLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7eafda6-c580-46a5-d2f5-f6a04a30f31e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting anchor-exp\n",
            "  Downloading anchor_exp-0.0.2.0.tar.gz (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from anchor-exp) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from anchor-exp) (1.10.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from anchor-exp) (3.5.2)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from anchor-exp) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->anchor-exp) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->anchor-exp) (3.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime->anchor-exp) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime->anchor-exp) (4.65.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime->anchor-exp) (0.19.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (67.7.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (1.1.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (8.1.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (3.1.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (1.10.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (1.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (2.27.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (2.4.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (2.0.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (6.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->anchor-exp) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->anchor-exp) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->anchor-exp) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->anchor-exp) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->anchor-exp) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->anchor-exp) (3.4)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->anchor-exp) (2023.4.12)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->anchor-exp) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->anchor-exp) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->anchor-exp) (8.4.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime->anchor-exp) (1.4.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->anchor-exp) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->anchor-exp) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy->anchor-exp) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->anchor-exp) (2.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->anchor-exp) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->anchor-exp) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->anchor-exp) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->anchor-exp) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->anchor-exp) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime->anchor-exp) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime->anchor-exp) (1.16.0)\n",
            "Building wheels for collected packages: anchor-exp, lime\n",
            "  Building wheel for anchor-exp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anchor-exp: filename=anchor_exp-0.0.2.0-py3-none-any.whl size=433519 sha256=ffddee50af5aca7f481006f985eb1c492a6560a415b68cf5d192a8cd21cfd676\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/53/45/7e4602020c5e5069ccef79f1389adb8efc4ca3c4d9891388bb\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283859 sha256=92e8203e7651d3d0a26b93e7976de48d21c37ef1970fcf0d4dbc7ec3549ebfeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built anchor-exp lime\n",
            "Installing collected packages: lime, anchor-exp\n",
            "Successfully installed anchor-exp-0.0.2.0 lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install anchor-exp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from anchor import utils\n",
        "from anchor import anchor_tabular\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yXY_zSv5mXM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data into a numpy array\n",
        "train_data = pd.read_csv(\"FICO.full.csv\")\n",
        "train_data=pd.DataFrame(train_data)\n",
        "train_data.to_csv(\"my_data.csv\")\n",
        "#data = pd.read_csv(\"my_data.csv\")\n",
        "data = np.genfromtxt(\"my_data.csv\", delimiter=\",\")\n",
        "data = data[1:]\n",
        "data = data[:,1:]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nn3-FQlPmBlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data into training and testing sets\n",
        "X_train, y_train = data[:, :-1], data[:, -1]\n",
        "\n",
        "# Train a random forest model on your training data\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
        "rf.fit(X_train, y_train)\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J5937TIr1nf",
        "outputId": "0d39e11b-898a-404d-878f-782cc7fdbb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10459, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that takes an instance and returns its predicted class label\n",
        "predict_fn = lambda x: rf.predict(x.reshape(1, -1)).ravel()\n",
        "\n",
        "# Define a function that checks if a given instance has a different class label than the original instance\n",
        "def has_different_label(x, original_label):\n",
        "    return rf.predict(x.reshape(1, -1)).ravel() != original_label\n",
        "\n",
        "# Define a function that searches for a counterfactual instance using the Anchors algorithm\n",
        "def search_counterfactual(x, original_label):\n",
        "    # Define the search parameters\n",
        "    search_params = {\n",
        "        \"sample_whole_training\": False,\n",
        "        \"seed\": 1\n",
        "    }\n",
        "\n",
        "    # Define the feature names and the class names\n",
        "    feature_names = [\"ExternalRiskEstimate<0.49\",\"ExternalRiskEstimate<0.65\",\"ExternalRiskEstimate<0.80\",\"NumSatisfactoryTrades<0.5\",\"TradeOpenTime<0.6\",\"TradeOpenTime<0.85\",\"TradeFrequency<0.45\",\"TradeFrequency<0.6\",\"Delinquency<0.55\",\"Delinquency<0.75\",\"Installment<0.5\",\"Installment<0.7\",\"Inquiry<0.75\",\"RevolvingBalance<0.4\",\"RevolvingBalance<0.6\",\"Utilization<0.6\",\"TradeWBalance<0.33\"]\n",
        "    class_names = [\"0\", \"1\"]\n",
        "\n",
        "    # Create an Anchors explainer object for your random forest model\n",
        "    explainer = anchor_tabular.AnchorTabularExplainer( class_names,feature_names,\n",
        "        X_train\n",
        "        \n",
        "    )\n",
        "\n",
        "    # Generate a counterfactual explanation for the given instance using Anchors\n",
        "    explanation = explainer.explain_instance(\n",
        "        x, rf.predict, threshold=0.95\n",
        "    )\n",
        "\n",
        "    # Search for a counterfactual instance that has a different class label\n",
        "    \n",
        "    cfe = explanation.examples(only_different_prediction=True)\n",
        "    cfe_set = []\n",
        "    for elt in cfe :\n",
        "      if has_different_label(elt, original_label):\n",
        "        cfe_set.append(elt)\n",
        "\n",
        "    return cfe\n",
        "\n"
      ],
      "metadata": {
        "id": "ukNzjS3JmF9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an example instance and its original class label\n",
        "instance = X_train[0]\n",
        "original_label = rf.predict(instance.reshape(1, -1)).ravel()[0]\n",
        "instance\n",
        "\n"
      ],
      "metadata": {
        "id": "nO0Fme4rmSkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358e015c-162c-4679-e65e-93205f000610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for a counterfactual instance that has a different class label\n",
        "counterfactual_set = search_counterfactual(instance, original_label)\n",
        "\n",
        "#if counterfactual_set:\n",
        "    #print(\"Counterfactual instance found:\", counterfactual_set)\n",
        "#else:\n",
        "    #print(\"Counterfactual instance not found.\")"
      ],
      "metadata": {
        "id": "kbBlBvoYx4ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counterfactual_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd9MHr-ZYdYi",
        "outputId": "544b11fa-5f01-4e18-908f-3dbef971cb8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "        1.],\n",
              "       [0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        0.],\n",
              "       [0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "        0.],\n",
              "       [0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1.],\n",
              "       [0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
              "        1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/marcotcr/anchor/blob/b1f5e6ca37428613723597e85c38558e8cd21c2e/anchor/anchor_explanation.py#L5\n",
        "# https://arxiv.org/pdf/1805.10820.pdf\n",
        "# https://github.com/riccotti/LORE/blob/master/test_lore.py"
      ],
      "metadata": {
        "id": "LQDlWXJ62iMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prepare_dataset import collectTreesRF, exportTreeCollection"
      ],
      "metadata": {
        "id": "NGbPZmOrNTmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_nodesRF, children_leftRF, children_rightRF, featureRF, thresholdRF, node_depthRF, is_leavesRF, nodeValuesRF = collectTreesRF(rf)\n",
        "exportTreeCollection(\"Ficofull\", \"RF\",  0, len(X_train[0]), len(rf.classes_),\n",
        "                             n_nodesRF, children_leftRF, children_rightRF, featureRF, thresholdRF,\n",
        "                             node_depthRF, is_leavesRF, nodeValuesRF)"
      ],
      "metadata": {
        "id": "vQTbmeX_Ngsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_region(vectors,filename) :\n",
        "    vectors = np.array(vectors)\n",
        "\n",
        "    min_vectors=np.min(vectors,axis=0)\n",
        "    max_vectors=np.max(vectors, axis=0)\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        np.savetxt(f, [min_vectors], fmt='%.2f', delimiter=',', newline='\\n')\n",
        "        np.savetxt(f, [max_vectors], fmt='%.2f', delimiter=',', newline='\\n')\n",
        "\n",
        "\n",
        "    return min_vectors, max_vectors"
      ],
      "metadata": {
        "id": "6e0DYc2mJGo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "our_set = list(counterfactual_set) \n",
        "our_set.append(instance)\n",
        "our_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtNDl1JXZDfR",
        "outputId": "7c7bdbb2-2c47-4339-d673-130c707d4bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.]),\n",
              " array([0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.]),\n",
              " array([0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.]),\n",
              " array([0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.])]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b = export_region(our_set,\"region_cf_set.txt\")"
      ],
      "metadata": {
        "id": "fLM5bu8lLMOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a,b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_yufHveLbez",
        "outputId": "b0133e52-61f1-4749-c814-88177ac5c944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.]),\n",
              " array([0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bo-9s_GoLcNc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}